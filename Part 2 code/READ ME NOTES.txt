HOW THE DIRECTORY IS STRUCTURED:



Data Folder: Holds the IBM training and testing data.

Results Folder: Holds results in visual format.

Saved agents Folder: Agents in saved pytorch format to be used by testing_script.py and agent_trade_visuals.py


agent_trade_visuals.py: Visualizes agent individual trades, saved in the Results folder.
data_utility.py: utility code for loading data from the  Data folder. Used by the training and testing scripts
helper_functions.py: Helper code for interacting with the environment. Used by the training scripts.
my_nn_architectures.py: Code for defining the Pytorch Neural Networks and loss functions for the several types of DQN. Used by the training scripts.
trading environment.py: The defined environment for simulating the stock market.

Training scripts: 3 scripts. 1 for each agent. DQN, DoubleDQN, DuelingDoubleDQN. The resulting agents are saved in Saved agents folder in pytorch format.



On trding_environment.py:  Resources for  this code include:

https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On-Second-Edition      
https://github.com/ShuaiW/teach-machine-to-trade
https://github.com/edwardhdlu/q-trader

The environment is a much simpler environment than the above.